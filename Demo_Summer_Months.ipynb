{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "kv8IKWeBZisr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12456,
     "status": "ok",
     "timestamp": 1681172666954,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "kv8IKWeBZisr",
    "outputId": "603a835b-88de-4f58-a5af-4bc55abbbf42",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (2.0.1.post0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pytorch-lightning) (1.23.4)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pytorch-lightning) (0.11.4)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pytorch-lightning) (4.5.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pytorch-lightning) (23.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pytorch-lightning) (2023.4.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pytorch-lightning) (0.8.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pytorch-lightning) (2.0.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pytorch-lightning) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: requests in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.28.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.99)\n",
      "Requirement already satisfied: jinja2 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.99)\n",
      "Requirement already satisfied: networkx in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (2.14.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.10.3.66)\n",
      "Requirement already satisfied: sympy in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
      "Requirement already satisfied: filelock in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.4.91)\n",
      "Requirement already satisfied: wheel in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->pytorch-lightning) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->pytorch-lightning) (66.0.0)\n",
      "Requirement already satisfied: lit in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.1)\n",
      "Requirement already satisfied: cmake in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.26.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ggIlo9-aaDF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1681172677062,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "4ggIlo9-aaDF",
    "outputId": "956794d5-73da-4f7a-b351-bad0d1f89a1f",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1420a6-ec32-41b6-91e7-6721bc0a68c5",
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1681172678598,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "1e1420a6-ec32-41b6-91e7-6721bc0a68c5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import tempfile\n",
    "import time\n",
    "import urllib\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "from typing import List\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45c1f7a-591c-4956-b944-6e0c11ba167b",
   "metadata": {
    "executionInfo": {
     "elapsed": 64459,
     "status": "ok",
     "timestamp": 1681172745368,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "b45c1f7a-591c-4956-b944-6e0c11ba167b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load preprocessed data from 10 nodes in the bay area\n",
    "\n",
    "# df = pd.read_csv(\"/content/drive/Shareddrives/DATA 298A  B- Electricity Price Prediction/New/processed.csv\")\n",
    "df = pd.read_csv(\"processed (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "GNJGZ7W-KQC8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1681168440180,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "GNJGZ7W-KQC8",
    "outputId": "cc9216ea-1d91-4717-d7b5-8c42b7755142",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>INTERVALSTARTTIME_GMT</th>\n",
       "      <th>INTERVALENDTIME_GMT</th>\n",
       "      <th>OPR_DT</th>\n",
       "      <th>OPR_HR</th>\n",
       "      <th>NODE_ID_XML</th>\n",
       "      <th>NODE_ID</th>\n",
       "      <th>NODE</th>\n",
       "      <th>MARKET_RUN_ID</th>\n",
       "      <th>LMP_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>2DA</th>\n",
       "      <th>7DA</th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>DAM</th>\n",
       "      <th>ETo (in)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Rel Hum (%)</th>\n",
       "      <th>Wind Speed (mph)</th>\n",
       "      <th>Soil Temp (F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01T08:00:00-00:00</td>\n",
       "      <td>2020-01-01T08:05:00-00:00</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>RTM</td>\n",
       "      <td>LMP</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4.146099</td>\n",
       "      <td>-4.113026</td>\n",
       "      <td>-4.485045</td>\n",
       "      <td>-4.307317</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>3.663296</td>\n",
       "      <td>-1.213782</td>\n",
       "      <td>0.188814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01T08:05:00-00:00</td>\n",
       "      <td>2020-01-01T08:10:00-00:00</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>RTM</td>\n",
       "      <td>LMP</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4.146099</td>\n",
       "      <td>-4.113026</td>\n",
       "      <td>-4.485045</td>\n",
       "      <td>-4.307317</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>3.663296</td>\n",
       "      <td>-1.213782</td>\n",
       "      <td>0.188814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01T08:10:00-00:00</td>\n",
       "      <td>2020-01-01T08:15:00-00:00</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>RTM</td>\n",
       "      <td>LMP</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4.146099</td>\n",
       "      <td>-4.113026</td>\n",
       "      <td>-4.485045</td>\n",
       "      <td>-4.307317</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>3.663296</td>\n",
       "      <td>-1.213782</td>\n",
       "      <td>0.188814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-01T08:15:00-00:00</td>\n",
       "      <td>2020-01-01T08:20:00-00:00</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>RTM</td>\n",
       "      <td>LMP</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4.146099</td>\n",
       "      <td>-4.113026</td>\n",
       "      <td>-4.485045</td>\n",
       "      <td>-4.307317</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>3.663296</td>\n",
       "      <td>-1.213782</td>\n",
       "      <td>0.188814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-01T08:20:00-00:00</td>\n",
       "      <td>2020-01-01T08:25:00-00:00</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>DIXONLD_1_N008</td>\n",
       "      <td>RTM</td>\n",
       "      <td>LMP</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4.146099</td>\n",
       "      <td>-4.113026</td>\n",
       "      <td>-4.485045</td>\n",
       "      <td>-4.307317</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>3.663296</td>\n",
       "      <td>-1.213782</td>\n",
       "      <td>0.188814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      INTERVALSTARTTIME_GMT        INTERVALENDTIME_GMT  \\\n",
       "0           0  2020-01-01T08:00:00-00:00  2020-01-01T08:05:00-00:00   \n",
       "1           1  2020-01-01T08:05:00-00:00  2020-01-01T08:10:00-00:00   \n",
       "2           2  2020-01-01T08:10:00-00:00  2020-01-01T08:15:00-00:00   \n",
       "3           3  2020-01-01T08:15:00-00:00  2020-01-01T08:20:00-00:00   \n",
       "4           4  2020-01-01T08:20:00-00:00  2020-01-01T08:25:00-00:00   \n",
       "\n",
       "       OPR_DT  OPR_HR     NODE_ID_XML         NODE_ID            NODE  \\\n",
       "0  2020-01-01       1  DIXONLD_1_N008  DIXONLD_1_N008  DIXONLD_1_N008   \n",
       "1  2020-01-01       1  DIXONLD_1_N008  DIXONLD_1_N008  DIXONLD_1_N008   \n",
       "2  2020-01-01       1  DIXONLD_1_N008  DIXONLD_1_N008  DIXONLD_1_N008   \n",
       "3  2020-01-01       1  DIXONLD_1_N008  DIXONLD_1_N008  DIXONLD_1_N008   \n",
       "4  2020-01-01       1  DIXONLD_1_N008  DIXONLD_1_N008  DIXONLD_1_N008   \n",
       "\n",
       "  MARKET_RUN_ID LMP_TYPE  ... HOUR       2DA       7DA    ACTUAL       DAM  \\\n",
       "0           RTM      LMP  ...   16 -4.146099 -4.113026 -4.485045 -4.307317   \n",
       "1           RTM      LMP  ...   16 -4.146099 -4.113026 -4.485045 -4.307317   \n",
       "2           RTM      LMP  ...   16 -4.146099 -4.113026 -4.485045 -4.307317   \n",
       "3           RTM      LMP  ...   16 -4.146099 -4.113026 -4.485045 -4.307317   \n",
       "4           RTM      LMP  ...   16 -4.146099 -4.113026 -4.485045 -4.307317   \n",
       "\n",
       "   ETo (in)  Precip (in)  Rel Hum (%)  Wind Speed (mph)  Soil Temp (F)  \n",
       "0 -3.023405     -0.03305     3.663296         -1.213782       0.188814  \n",
       "1 -3.023405     -0.03305     3.663296         -1.213782       0.188814  \n",
       "2 -3.023405     -0.03305     3.663296         -1.213782       0.188814  \n",
       "3 -3.023405     -0.03305     3.663296         -1.213782       0.188814  \n",
       "4 -3.023405     -0.03305     3.663296         -1.213782       0.188814  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fD2Ta4RYKhjG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1681168442679,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "fD2Ta4RYKhjG",
    "outputId": "daa9fd7c-a736-47e5-a84b-a01ccd7cc2fb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NODE\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023e61bb-6d5c-4b7f-b8cb-13748a2023d4",
   "metadata": {
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1681172746167,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "023e61bb-6d5c-4b7f-b8cb-13748a2023d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"INTERVALENDTIME_GMT\",\n",
    "        \"OPR_DT\",\n",
    "        \"OPR_HR\",\n",
    "        \"NODE_ID_XML\",\n",
    "        \"NODE\",\n",
    "        \"NODE_ID\",\n",
    "        \"MARKET_RUN_ID\",\n",
    "        \"LMP_TYPE\",\n",
    "        \"XML_DATA_ITEM\",\n",
    "        \"PNODE_RESMRID\",\n",
    "        \"GRP_TYPE\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "iIAlEU6YbKog",
   "metadata": {
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1681172756235,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "iIAlEU6YbKog",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"INTERVALSTARTTIME_GMT\"] = pd.to_datetime(df[\"INTERVALSTARTTIME_GMT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "K1ErwooubEMh",
   "metadata": {
    "executionInfo": {
     "elapsed": 1123,
     "status": "ok",
     "timestamp": 1681172758363,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "K1ErwooubEMh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[\n",
    "    (\n",
    "        (df[\"INTERVALSTARTTIME_GMT\"].dt.month > 4)\n",
    "        & (df[\"INTERVALSTARTTIME_GMT\"].dt.month < 10)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "FCxOrCEZGAMW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1681172760315,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "FCxOrCEZGAMW",
    "outputId": "dafec027-12b3-4bf8-b02d-d697c5925d2f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"INTERVALSTARTTIME_GMT\"].dt.month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "-nh59iLBF2Jb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1681172763018,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "-nh59iLBF2Jb",
    "outputId": "c7330803-56c6-4a61-cf4c-c04811c6e233",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2020, 2021, 2022])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"INTERVALSTARTTIME_GMT\"].dt.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a88391ab-79b4-46c3-8d96-5aac40747154",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681172764773,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "a88391ab-79b4-46c3-8d96-5aac40747154",
    "outputId": "3ada103a-7991-46d9-8d00-03582086cd4f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 958392 rows\n",
      "Test:  319464 rows\n",
      "\n",
      "Train set shape: (958392, 15)\n",
      "Test set shape:  (319464, 15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set_length = int(round((df.shape[0] * 0.75), 0))\n",
    "test_set_length = df.shape[0] - train_set_length\n",
    "\n",
    "print(f\"\\nTrain: {train_set_length} rows\\nTest:  {test_set_length} rows\")\n",
    "\n",
    "train = df.iloc[:train_set_length]\n",
    "test = df.iloc[train_set_length:]\n",
    "\n",
    "print(f\"\\nTrain set shape: {train.shape}\\nTest set shape:  {test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03dfa697-7530-4d0a-b52a-47d852ec4604",
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1681172768531,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "03dfa697-7530-4d0a-b52a-47d852ec4604",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.set_index(\"INTERVALSTARTTIME_GMT\")\n",
    "test = test.set_index(\"INTERVALSTARTTIME_GMT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb9d003-fc88-4183-b883-98eb1b4f0f27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1681172770901,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "4eb9d003-fc88-4183-b883-98eb1b4f0f27",
    "outputId": "d6ef8927-99fd-4299-a33b-e83901569e1c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "['POS', 'OPR_INTERVAL', 'GROUP', 'HOUR', '2DA', '7DA', 'ACTUAL', 'DAM', 'ETo (in)', 'Precip (in)', 'Rel Hum (%)', 'Wind Speed (mph)', 'Soil Temp (F)']\n"
     ]
    }
   ],
   "source": [
    "features = [col for col in train.columns if col != \"VALUE\"]\n",
    "print(len(features))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e9be8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>OPR_INTERVAL</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>2DA</th>\n",
       "      <th>7DA</th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>DAM</th>\n",
       "      <th>ETo (in)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Rel Hum (%)</th>\n",
       "      <th>Wind Speed (mph)</th>\n",
       "      <th>Soil Temp (F)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERVALSTARTTIME_GMT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-01 00:00:00+00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.744149</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.327543</td>\n",
       "      <td>-2.446943</td>\n",
       "      <td>-3.077697</td>\n",
       "      <td>-2.811133</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>2.138363</td>\n",
       "      <td>-2.159378</td>\n",
       "      <td>3.209224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01 00:05:00+00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.760948</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.327543</td>\n",
       "      <td>-2.446943</td>\n",
       "      <td>-3.077697</td>\n",
       "      <td>-2.811133</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>2.138363</td>\n",
       "      <td>-2.159378</td>\n",
       "      <td>3.209224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01 00:10:00+00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.753703</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.327543</td>\n",
       "      <td>-2.446943</td>\n",
       "      <td>-3.077697</td>\n",
       "      <td>-2.811133</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>2.138363</td>\n",
       "      <td>-2.159378</td>\n",
       "      <td>3.209224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01 00:15:00+00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.765075</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.327543</td>\n",
       "      <td>-2.446943</td>\n",
       "      <td>-3.077697</td>\n",
       "      <td>-2.811133</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>2.138363</td>\n",
       "      <td>-2.159378</td>\n",
       "      <td>3.209224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01 00:20:00+00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.790930</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.327543</td>\n",
       "      <td>-2.446943</td>\n",
       "      <td>-3.077697</td>\n",
       "      <td>-2.811133</td>\n",
       "      <td>-3.023405</td>\n",
       "      <td>-0.03305</td>\n",
       "      <td>2.138363</td>\n",
       "      <td>-2.159378</td>\n",
       "      <td>3.209224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           POS     VALUE  OPR_INTERVAL  GROUP  HOUR       2DA  \\\n",
       "INTERVALSTARTTIME_GMT                                                           \n",
       "2020-05-01 00:00:00+00:00    1 -0.744149             1      5     8 -3.327543   \n",
       "2020-05-01 00:05:00+00:00    1 -0.760948             2      5     8 -3.327543   \n",
       "2020-05-01 00:10:00+00:00    1 -0.753703             3      5     8 -3.327543   \n",
       "2020-05-01 00:15:00+00:00    1 -0.765075             4      5     8 -3.327543   \n",
       "2020-05-01 00:20:00+00:00    1 -0.790930             5      5     8 -3.327543   \n",
       "\n",
       "                                7DA    ACTUAL       DAM  ETo (in)  \\\n",
       "INTERVALSTARTTIME_GMT                                               \n",
       "2020-05-01 00:00:00+00:00 -2.446943 -3.077697 -2.811133 -3.023405   \n",
       "2020-05-01 00:05:00+00:00 -2.446943 -3.077697 -2.811133 -3.023405   \n",
       "2020-05-01 00:10:00+00:00 -2.446943 -3.077697 -2.811133 -3.023405   \n",
       "2020-05-01 00:15:00+00:00 -2.446943 -3.077697 -2.811133 -3.023405   \n",
       "2020-05-01 00:20:00+00:00 -2.446943 -3.077697 -2.811133 -3.023405   \n",
       "\n",
       "                           Precip (in)  Rel Hum (%)  Wind Speed (mph)  \\\n",
       "INTERVALSTARTTIME_GMT                                                   \n",
       "2020-05-01 00:00:00+00:00     -0.03305     2.138363         -2.159378   \n",
       "2020-05-01 00:05:00+00:00     -0.03305     2.138363         -2.159378   \n",
       "2020-05-01 00:10:00+00:00     -0.03305     2.138363         -2.159378   \n",
       "2020-05-01 00:15:00+00:00     -0.03305     2.138363         -2.159378   \n",
       "2020-05-01 00:20:00+00:00     -0.03305     2.138363         -2.159378   \n",
       "\n",
       "                           Soil Temp (F)  \n",
       "INTERVALSTARTTIME_GMT                     \n",
       "2020-05-01 00:00:00+00:00       3.209224  \n",
       "2020-05-01 00:05:00+00:00       3.209224  \n",
       "2020-05-01 00:10:00+00:00       3.209224  \n",
       "2020-05-01 00:15:00+00:00       3.209224  \n",
       "2020-05-01 00:20:00+00:00       3.209224  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36599712-5490-4127-84b4-a7a737f0129b",
   "metadata": {
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1681172772157,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "36599712-5490-4127-84b4-a7a737f0129b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[\"VALUE\"]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[\"VALUE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c89e7-b921-423c-95e9-3a224ca0c442",
   "metadata": {
    "id": "6b8c89e7-b921-423c-95e9-3a224ca0c442"
   },
   "source": [
    "# Classic Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4f1db-5137-4ef8-a97c-622262892bd1",
   "metadata": {
    "id": "3bd4f1db-5137-4ef8-a97c-622262892bd1"
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "Linear Regression is the most basic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b339c3d-a7b7-4fc9-8207-9c38c5518a51",
   "metadata": {
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1681172854004,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "8b339c3d-a7b7-4fc9-8207-9c38c5518a51",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'DIXONLD_1_N008'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m----> 3\u001b[0m reg \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    654\u001b[0m )\n\u001b[1;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[1;32m    657\u001b[0m     X,\n\u001b[1;32m    658\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    662\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'DIXONLD_1_N008'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab50126-38cd-4a62-8d0d-66be2c184427",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681172855822,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "2ab50126-38cd-4a62-8d0d-66be2c184427",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mreg\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test_sc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reg' is not defined"
     ]
    }
   ],
   "source": [
    "prediction = reg.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3fd6667-ef1c-4a2e-81e2-584dd0983c5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3fd6667-ef1c-4a2e-81e2-584dd0983c5a",
    "outputId": "f8bf9d22-c1d6-4903-c14d-dae90a5399fa",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error \u001b[38;5;28;01mas\u001b[39;00m mse\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m----> 5\u001b[0m score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse(y_test, \u001b[43mprediction\u001b[49m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE Score on LinearRegression Test set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, prediction)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "score = np.sqrt(mse(y_test, prediction))\n",
    "print(f\"RMSE Score on LinearRegression Test set: {score:0.3f}\")\n",
    "mae = mean_absolute_error(y_test, prediction)\n",
    "print(f\"MAE Score on LinearRegression Test set: {mae:0.3f}\")\n",
    "mape = mean_absolute_percentage_error(y_test, prediction)\n",
    "print(f\"MAPE Score on LinearRegression Test set: {mape:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30523bc-d82e-49d1-ae64-ea6fcaad75f2",
   "metadata": {
    "id": "a30523bc-d82e-49d1-ae64-ea6fcaad75f2"
   },
   "source": [
    "## XGBoost\n",
    "\n",
    "XGBoost (eXtreme Gradient Boosting) is an open-source software library which provides a regularizing gradient boosting framework. It aims to provide a \"Scalable, Portable and Distributed Gradient Boosting (GBM, GBRT, GBDT) Library\". It runs on a single machine, as well as the distributed processing frameworks Apache Hadoop, Apache Spark, Apache Flink, and Dask.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79224371-6f7e-4f40-8f9f-dd3eab18e5e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 611079,
     "status": "ok",
     "timestamp": 1681173485772,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "79224371-6f7e-4f40-8f9f-dd3eab18e5e6",
    "outputId": "2d801df0-f6f1-4d97-a957-66cb08b9eebd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:27:56] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.21653\tvalidation_1-rmse:1.23416\n",
      "[100]\tvalidation_0-rmse:1.04097\tvalidation_1-rmse:1.12456\n",
      "[200]\tvalidation_0-rmse:1.00343\tvalidation_1-rmse:1.11322\n",
      "[278]\tvalidation_0-rmse:0.99538\tvalidation_1-rmse:1.11310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=10000, n_jobs=None, num_parallel_tree=None,\n",
       "             objective=&#x27;reg:linear&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=10000, n_jobs=None, num_parallel_tree=None,\n",
       "             objective=&#x27;reg:linear&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=10000, n_jobs=None, num_parallel_tree=None,\n",
       "             objective='reg:linear', predictor=None, ...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "reg = xgb.XGBRegressor(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    n_estimators=10000,\n",
    "    early_stopping_rounds=50,\n",
    "    objective=\"reg:linear\",\n",
    "    max_depth=10,\n",
    "    learning_rate=0.01,\n",
    ")\n",
    "reg.fit(\n",
    "    X_train_sc,\n",
    "    y_train,\n",
    "    eval_set=[(X_train_sc, y_train), (X_test_sc, y_test)],\n",
    "    verbose=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "426b045f-4bc2-470c-9617-57efa1d9c396",
   "metadata": {
    "executionInfo": {
     "elapsed": 4455,
     "status": "ok",
     "timestamp": 1681174820103,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "426b045f-4bc2-470c-9617-57efa1d9c396",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = reg.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "hUN-RQ5k02n1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1681174821403,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "hUN-RQ5k02n1",
    "outputId": "75bcce77-181f-4e5a-fa7c-65e8c268ac0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score on XGBRegressor Test set: 1.113\n",
      "MAE Score on XGBRegressor Test set: 0.437\n",
      "MAPE Score on XGBRegressor Test set: 3.082\n"
     ]
    }
   ],
   "source": [
    "score = np.sqrt(mse(y_test, prediction))\n",
    "print(f\"RMSE Score on XGBRegressor Test set: {score:0.3f}\")\n",
    "mae = mean_absolute_error(y_test, prediction)\n",
    "print(f\"MAE Score on XGBRegressor Test set: {mae:0.3f}\")\n",
    "mape = mean_absolute_percentage_error(y_test, prediction)\n",
    "print(f\"MAPE Score on XGBRegressor Test set: {mape:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c7b60-8e68-46f4-9f26-0a2d3fcb5565",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de4c7b60-8e68-46f4-9f26-0a2d3fcb5565",
    "outputId": "354673ec-65f8-4674-d3ad-1abe9e43ddcb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score on XGBRegressor Test set: 1.113\n",
      "MAE Score on XGBRegressor Test set: 0.437\n",
      "MAPE Score on XGBRegressor Test set: 3.082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "score = np.sqrt(mse(y_test, prediction))\n",
    "print(f\"RMSE Score on XGBRegressor Test set: {score:0.3f}\")\n",
    "mae = mean_absolute_error(y_test, prediction)\n",
    "print(f\"MAE Score on XGBRegressor Test set: {mae:0.3f}\")\n",
    "mape = mean_absolute_percentage_error(y_test, prediction)\n",
    "print(f\"MAPE Score on XGBRegressor Test set: {mape:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e2d89-e0fa-483c-8b29-1580eb97d194",
   "metadata": {
    "id": "7c9e2d89-e0fa-483c-8b29-1580eb97d194"
   },
   "source": [
    "# Innovative Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb73f8-eb9e-4797-a320-a5b4a8630263",
   "metadata": {
    "id": "a4bb73f8-eb9e-4797-a320-a5b4a8630263"
   },
   "source": [
    "## RNN (LSTM, GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fa11cb2-3b9c-48ba-a174-ee6d31bb8e40",
   "metadata": {
    "id": "7fa11cb2-3b9c-48ba-a174-ee6d31bb8e40",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m regularizers\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GRU, LSTM, Dense, Dropout\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from keras.layers import GRU, LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13442886-d978-4fab-bae3-e6b4d4f37cb9",
   "metadata": {
    "id": "13442886-d978-4fab-bae3-e6b4d4f37cb9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time Series Generator Parameters\n",
    "\n",
    "lookback_length = 12\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa13ea2-093c-4819-8adf-65cd12837fd7",
   "metadata": {
    "id": "0fa13ea2-093c-4819-8adf-65cd12837fd7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sequences = TimeseriesGenerator(\n",
    "    X_train, y_train, length=lookback_length, batch_size=batch_size\n",
    ")\n",
    "batch_x, batch_y = train_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e8b98-051a-4930-84a5-51b775081f2a",
   "metadata": {
    "id": "840e8b98-051a-4930-84a5-51b775081f2a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sequences = TimeseriesGenerator(\n",
    "    X_test, y_test, length=lookback_length, batch_size=batch_size\n",
    ")\n",
    "\n",
    "batch_x_test, batch_y_test = test_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba96c1a3-41d8-47ff-93e5-3cbb8b80f43c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba96c1a3-41d8-47ff-93e5-3cbb8b80f43c",
    "outputId": "15dff1be-00de-466c-a7f8-f2cdc4f092b8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 12, 16)            1488      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 16)                1632      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                544       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,337\n",
      "Trainable params: 4,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        GRU(16, input_shape=(batch_x.shape[1], batch_x.shape[2]), return_sequences=True)\n",
    "    )\n",
    "\n",
    "    model.add(GRU(16))\n",
    "\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    # model.add(Dropout(0.1))                  # refers to nodes in the first hidden layer\n",
    "\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    # model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    # model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c7653-b874-4bea-a47c-3913cdac2d23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c7c7653-b874-4bea-a47c-3913cdac2d23",
    "outputId": "52dd8318-cc65-47f0-e7c3-29124975eccb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "<ipython-input-42-770d6bfa73b1>:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14975/14975 [==============================] - 406s 27ms/step - loss: 1.1765 - val_loss: 1.2882\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model.compile(optimizer=Adam(lr=0.0005), loss=\"mean_squared_error\")\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        train_sequences,\n",
    "        validation_data=test_sequences,\n",
    "        epochs=1,\n",
    "        verbose=1,\n",
    "        use_multiprocessing=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e658c0d-e4b5-4ec9-9379-d8c348c671c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e658c0d-e4b5-4ec9-9379-d8c348c671c7",
    "outputId": "bb13d59c-f1f1-413c-97ce-78ad074d383c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 12ms/step\n",
      "RMSE Score on GRU Test set: 0.367\n",
      "MAE Score on GRU Test set: 0.356\n",
      "MAPE Score on GRU Test set: 2.792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pred = model.predict(batch_x_test)\n",
    "score = np.sqrt(mse(pred, batch_y_test))\n",
    "print(f\"RMSE Score on GRU Test set: {score:0.3f}\")\n",
    "mae = mean_absolute_error(pred, batch_y_test)\n",
    "print(f\"MAE Score on GRU Test set: {mae:0.3f}\")\n",
    "mape = mean_absolute_percentage_error(pred, batch_y_test)\n",
    "print(f\"MAPE Score on GRU Test set: {mape:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65c69e-dbbb-44da-acfa-0d190533ab50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c65c69e-dbbb-44da-acfa-0d190533ab50",
    "outputId": "83056dc4-cd01-4a69-f4e2-fa357cd9a37d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 12, 120)           64320     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 12, 80)            64320     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 40)                19360     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 148,041\n",
      "Trainable params: 148,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# %%LSTM Model\n",
    "model1 = Sequential()\n",
    "model1.add(\n",
    "    LSTM(\n",
    "        120,\n",
    "        return_sequences=True,\n",
    "        input_shape=(batch_x.shape[1], batch_x.shape[2]),\n",
    "    )\n",
    ")\n",
    "model1.add(LSTM(80, return_sequences=True))\n",
    "model1.add(LSTM(40))\n",
    "model1.add(Dense(1))\n",
    "model1.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70810c8b-1c95-43ba-b0b3-6cc299efb92e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70810c8b-1c95-43ba-b0b3-6cc299efb92e",
    "outputId": "3f8a459e-a00f-453b-acbf-0a81b6c9e492",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/14975 [..............................] - ETA: 14:52 - loss: 1.6660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "<ipython-input-45-304cf22a4f47>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history1 = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14975/14975 [==============================] - 344s 23ms/step - loss: 1.1631 - val_loss: 1.3209\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "model1.compile(optimizer=Adam(lr=0.0005), loss=\"mean_squared_error\")\n",
    "\n",
    "history1 = model.fit_generator(\n",
    "    train_sequences, validation_data=test_sequences, epochs=1, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f0dd1-7314-4c42-bc8f-7ec757cd856a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d08f0dd1-7314-4c42-bc8f-7ec757cd856a",
    "outputId": "7604cb81-6120-4e98-8718-8ca37d0a2593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step\n",
      "RMSE Score on LSTM Test set: 0.281\n",
      "MAE Score on LSTM Test set: 0.272\n",
      "MAPE Score on LSTM Test set: 1.211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pred = model.predict(batch_x_test)\n",
    "score = np.sqrt(mse(pred, batch_y_test))\n",
    "print(f\"RMSE Score on LSTM Test set: {score:0.3f}\")\n",
    "mae = mean_absolute_error(pred, batch_y_test)\n",
    "print(f\"MAE Score on LSTM Test set: {mae:0.3f}\")\n",
    "mape = mean_absolute_percentage_error(pred, batch_y_test)\n",
    "print(f\"MAPE Score on LSTM Test set: {mape:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jc6dD5lhcyVt",
   "metadata": {
    "id": "Jc6dD5lhcyVt"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jGFSg2Yw7CW6",
   "metadata": {
    "id": "jGFSg2Yw7CW6"
   },
   "outputs": [],
   "source": [
    "# Transformer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r_l8ABAo702S",
   "metadata": {
    "id": "r_l8ABAo702S"
   },
   "outputs": [],
   "source": [
    "# Attention layer\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TmAYBkbO70_2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93405,
     "status": "ok",
     "timestamp": 1681168657209,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "TmAYBkbO70_2",
    "outputId": "1b5e7074-85e2-451b-f23f-f2ad6375541a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.8919 - val_loss: 0.9766\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.9240 - val_loss: 0.8833\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.7527 - val_loss: 0.7989\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.6030 - val_loss: 0.7233\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.6425 - val_loss: 0.6532\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5824 - val_loss: 0.5887\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.5290 - val_loss: 0.5295\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5291 - val_loss: 0.4761\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.4357 - val_loss: 0.4277\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.4719 - val_loss: 0.3864\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.4164 - val_loss: 0.3518\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.4135 - val_loss: 0.3233\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.4120 - val_loss: 0.2995\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.4461 - val_loss: 0.2810\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.4362 - val_loss: 0.2670\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4140 - val_loss: 0.2548\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.4449 - val_loss: 0.2450\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.3875 - val_loss: 0.2375\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.3840 - val_loss: 0.2326\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.3893 - val_loss: 0.2291\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.3836 - val_loss: 0.2270\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.3475 - val_loss: 0.2252\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.4416 - val_loss: 0.2237\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.4285 - val_loss: 0.2226\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.4204 - val_loss: 0.2215\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.4101 - val_loss: 0.2206\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.3731 - val_loss: 0.2199\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.3574 - val_loss: 0.2192\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.3243 - val_loss: 0.2190\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.2834 - val_loss: 0.2188\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.3901 - val_loss: 0.2189\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.3700 - val_loss: 0.2190\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3648 - val_loss: 0.2184\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3249 - val_loss: 0.2177\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.3345 - val_loss: 0.2168\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3069 - val_loss: 0.2155\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.3504 - val_loss: 0.2142\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.2992 - val_loss: 0.2129\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3075 - val_loss: 0.2116\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.2983 - val_loss: 0.2101\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.2938 - val_loss: 0.2086\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3043 - val_loss: 0.2067\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2805 - val_loss: 0.2042\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.2787 - val_loss: 0.2017\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.2889 - val_loss: 0.1991\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3160 - val_loss: 0.1965\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.2725 - val_loss: 0.1934\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.2843 - val_loss: 0.1905\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.2660 - val_loss: 0.1877\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3079 - val_loss: 0.1853\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2606 - val_loss: 0.1832\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.2572 - val_loss: 0.1815\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.2836 - val_loss: 0.1799\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.2744 - val_loss: 0.1782\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.2826 - val_loss: 0.1770\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.2736 - val_loss: 0.1754\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.2579 - val_loss: 0.1735\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.2649 - val_loss: 0.1717\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.2799 - val_loss: 0.1697\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.2867 - val_loss: 0.1676\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3062 - val_loss: 0.1656\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.2494 - val_loss: 0.1637\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.2533 - val_loss: 0.1619\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.2423 - val_loss: 0.1600\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.2394 - val_loss: 0.1581\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.2172 - val_loss: 0.1562\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.2702 - val_loss: 0.1542\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.2910 - val_loss: 0.1522\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.2138 - val_loss: 0.1501\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.2475 - val_loss: 0.1480\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2132 - val_loss: 0.1458\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.2603 - val_loss: 0.1437\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.2343 - val_loss: 0.1414\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.2113 - val_loss: 0.1390\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.2170 - val_loss: 0.1367\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.2597 - val_loss: 0.1343\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.2249 - val_loss: 0.1320\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.2407 - val_loss: 0.1295\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1924 - val_loss: 0.1268\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.2639 - val_loss: 0.1241\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2090 - val_loss: 0.1213\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2022 - val_loss: 0.1185\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.2067 - val_loss: 0.1155\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.2630 - val_loss: 0.1126\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1922 - val_loss: 0.1097\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1949 - val_loss: 0.1067\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.1483 - val_loss: 0.1035\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.1872 - val_loss: 0.1002\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1741 - val_loss: 0.0970\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2097 - val_loss: 0.0935\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1877 - val_loss: 0.0900\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1766 - val_loss: 0.0866\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1628 - val_loss: 0.0832\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.2159 - val_loss: 0.0797\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.2008 - val_loss: 0.0762\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1368 - val_loss: 0.0727\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1940 - val_loss: 0.0691\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1699 - val_loss: 0.0653\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1944 - val_loss: 0.0615\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1615 - val_loss: 0.0576\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1536 - val_loss: 0.0537\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1579 - val_loss: 0.0501\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1684 - val_loss: 0.0465\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1509 - val_loss: 0.0431\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.1258 - val_loss: 0.0398\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.1155 - val_loss: 0.0365\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1558 - val_loss: 0.0334\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1485 - val_loss: 0.0307\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.1004 - val_loss: 0.0285\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.1217 - val_loss: 0.0265\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1012 - val_loss: 0.0248\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1085 - val_loss: 0.0233\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0914 - val_loss: 0.0222\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1115 - val_loss: 0.0214\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1107 - val_loss: 0.0209\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.1154 - val_loss: 0.0206\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 1s 500ms/step - loss: 0.0971 - val_loss: 0.0205\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.1164 - val_loss: 0.0205\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.1100 - val_loss: 0.0206\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0685 - val_loss: 0.0208\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0717 - val_loss: 0.0209\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0738 - val_loss: 0.0212\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.1116 - val_loss: 0.0213\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0874 - val_loss: 0.0213\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.1067 - val_loss: 0.0212\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1281 - val_loss: 0.0208\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.1310 - val_loss: 0.0203\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1179 - val_loss: 0.0199\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1065 - val_loss: 0.0195\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0814 - val_loss: 0.0194\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0936 - val_loss: 0.0193\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0738 - val_loss: 0.0193\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0816 - val_loss: 0.0193\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0748 - val_loss: 0.0192\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0807 - val_loss: 0.0191\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0919 - val_loss: 0.0190\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0977 - val_loss: 0.0189\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0964 - val_loss: 0.0186\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0981 - val_loss: 0.0184\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0686 - val_loss: 0.0182\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0873 - val_loss: 0.0180\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0670 - val_loss: 0.0181\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0587 - val_loss: 0.0182\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0602 - val_loss: 0.0184\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0783 - val_loss: 0.0185\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0794 - val_loss: 0.0187\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0732 - val_loss: 0.0189\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0771 - val_loss: 0.0190\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0573 - val_loss: 0.0191\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0806 - val_loss: 0.0190\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0667 - val_loss: 0.0191\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0261\n",
      "The execution time for Transformer model  33.02640724182129 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train transformer model\n",
    "input_shape = batch_x.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=1e-4)\n",
    ")\n",
    "# model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    batch_x,\n",
    "    batch_y,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "start_time = time.time()\n",
    "model.evaluate(batch_x_test, batch_y_test, verbose=1)\n",
    "print(\n",
    "    \"The execution time for Transformer model  %s seconds\" % (time.time() - start_time)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rSpmBk-S71Ml",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1338,
     "status": "ok",
     "timestamp": 1681168682854,
     "user": {
      "displayName": "Shamama Afnan",
      "userId": "18119871591444313216"
     },
     "user_tz": 420
    },
    "id": "rSpmBk-S71Ml",
    "outputId": "b4247888-24f1-419c-c33d-7f55416a4dc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 61ms/step\n",
      "RMSE Score on Transformer Test set: 0.162\n",
      "MAE Score on Transformer Test set: 0.124\n",
      "MAPE Score on Transformer Test set: 0.396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pred = model.predict(batch_x_test)\n",
    "score = np.sqrt(mse(pred, batch_y_test))\n",
    "print(f\"RMSE Score on Transformer Test set: {score:0.3f}\")\n",
    "mae = mean_absolute_error(pred, batch_y_test)\n",
    "print(f\"MAE Score on Transformer Test set: {mae:0.3f}\")\n",
    "mape = mean_absolute_percentage_error(pred, batch_y_test)\n",
    "print(f\"MAPE Score on Transformer Test set: {mape:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rcoNqd9ic0nu",
   "metadata": {
    "id": "rcoNqd9ic0nu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3073b257-4cc6-48cd-a2b5-959f10a1c330",
   "metadata": {
    "id": "3073b257-4cc6-48cd-a2b5-959f10a1c330"
   },
   "source": [
    "## Our Proposed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7fa717fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def get_emb(sin_inp):\n",
    "    \"\"\"\n",
    "    Gets a base embedding for one dimension with sin and cos intertwined\n",
    "    \"\"\"\n",
    "    emb = torch.stack((sin_inp.sin(), sin_inp.cos()), dim=-1)\n",
    "    return torch.flatten(emb, -2, -1)\n",
    "\n",
    "\n",
    "class PositionalEncoding1D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding1D, self).__init__()\n",
    "        self.org_channels = channels\n",
    "        channels = int(np.ceil(channels / 2) * 2)\n",
    "        self.channels = channels\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "        self.cached_penc = None\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: A 3d tensor of size (batch_size, x, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 3:\n",
    "            raise RuntimeError(\"The input tensor has to be 3d!\")\n",
    "\n",
    "        if self.cached_penc is not None and self.cached_penc.shape == tensor.shape:\n",
    "            return self.cached_penc\n",
    "\n",
    "        self.cached_penc = None\n",
    "        batch_size, x, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        emb_x = get_emb(sin_inp_x)\n",
    "        emb = torch.zeros((x, self.channels), device=tensor.device).type(tensor.type())\n",
    "        emb[:, : self.channels] = emb_x\n",
    "\n",
    "        self.cached_penc = emb[None, :, :orig_ch].repeat(batch_size, 1, 1)\n",
    "        return self.cached_penc\n",
    "\n",
    "\n",
    "class PositionalEncodingPermute1D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        Accepts (batchsize, ch, x) instead of (batchsize, x, ch)\n",
    "        \"\"\"\n",
    "        super(PositionalEncodingPermute1D, self).__init__()\n",
    "        self.penc = PositionalEncoding1D(channels)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        tensor = tensor.permute(0, 2, 1)\n",
    "        enc = self.penc(tensor)\n",
    "        return enc.permute(0, 2, 1)\n",
    "\n",
    "    @property\n",
    "    def org_channels(self):\n",
    "        return self.penc.org_channels\n",
    "\n",
    "\n",
    "class PositionalEncoding2D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding2D, self).__init__()\n",
    "        self.org_channels = channels\n",
    "        channels = int(np.ceil(channels / 4) * 2)\n",
    "        self.channels = channels\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "        self.cached_penc = None\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: A 4d tensor of size (batch_size, x, y, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, y, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 4:\n",
    "            raise RuntimeError(\"The input tensor has to be 4d!\")\n",
    "\n",
    "        if self.cached_penc is not None and self.cached_penc.shape == tensor.shape:\n",
    "            return self.cached_penc\n",
    "\n",
    "        self.cached_penc = None\n",
    "        batch_size, x, y, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_y = torch.arange(y, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        sin_inp_y = torch.einsum(\"i,j->ij\", pos_y, self.inv_freq)\n",
    "        emb_x = get_emb(sin_inp_x).unsqueeze(1)\n",
    "        emb_y = get_emb(sin_inp_y)\n",
    "        emb = torch.zeros((x, y, self.channels * 2), device=tensor.device).type(\n",
    "            tensor.type()\n",
    "        )\n",
    "        emb[:, :, : self.channels] = emb_x\n",
    "        emb[:, :, self.channels : 2 * self.channels] = emb_y\n",
    "\n",
    "        self.cached_penc = emb[None, :, :, :orig_ch].repeat(tensor.shape[0], 1, 1, 1)\n",
    "        return self.cached_penc\n",
    "\n",
    "\n",
    "class PositionalEncodingPermute2D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        Accepts (batchsize, ch, x, y) instead of (batchsize, x, y, ch)\n",
    "        \"\"\"\n",
    "        super(PositionalEncodingPermute2D, self).__init__()\n",
    "        self.penc = PositionalEncoding2D(channels)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        tensor = tensor.permute(0, 2, 3, 1)\n",
    "        enc = self.penc(tensor)\n",
    "        return enc.permute(0, 3, 1, 2)\n",
    "\n",
    "    @property\n",
    "    def org_channels(self):\n",
    "        return self.penc.org_channels\n",
    "\n",
    "\n",
    "class PositionalEncoding3D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding3D, self).__init__()\n",
    "        self.org_channels = channels\n",
    "        channels = int(np.ceil(channels / 6) * 2)\n",
    "        if channels % 2:\n",
    "            channels += 1\n",
    "        self.channels = channels\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "        self.cached_penc = None\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: A 5d tensor of size (batch_size, x, y, z, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, y, z, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 5:\n",
    "            raise RuntimeError(\"The input tensor has to be 5d!\")\n",
    "\n",
    "        if self.cached_penc is not None and self.cached_penc.shape == tensor.shape:\n",
    "            return self.cached_penc\n",
    "\n",
    "        self.cached_penc = None\n",
    "        batch_size, x, y, z, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_y = torch.arange(y, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_z = torch.arange(z, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        sin_inp_y = torch.einsum(\"i,j->ij\", pos_y, self.inv_freq)\n",
    "        sin_inp_z = torch.einsum(\"i,j->ij\", pos_z, self.inv_freq)\n",
    "        emb_x = get_emb(sin_inp_x).unsqueeze(1).unsqueeze(1)\n",
    "        emb_y = get_emb(sin_inp_y).unsqueeze(1)\n",
    "        emb_z = get_emb(sin_inp_z)\n",
    "        emb = torch.zeros((x, y, z, self.channels * 3), device=tensor.device).type(\n",
    "            tensor.type()\n",
    "        )\n",
    "        emb[:, :, :, : self.channels] = emb_x\n",
    "        emb[:, :, :, self.channels : 2 * self.channels] = emb_y\n",
    "        emb[:, :, :, 2 * self.channels :] = emb_z\n",
    "\n",
    "        self.cached_penc = emb[None, :, :, :, :orig_ch].repeat(batch_size, 1, 1, 1, 1)\n",
    "        return self.cached_penc\n",
    "\n",
    "\n",
    "class PositionalEncodingPermute3D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        Accepts (batchsize, ch, x, y, z) instead of (batchsize, x, y, z, ch)\n",
    "        \"\"\"\n",
    "        super(PositionalEncodingPermute3D, self).__init__()\n",
    "        self.penc = PositionalEncoding3D(channels)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        tensor = tensor.permute(0, 2, 3, 4, 1)\n",
    "        enc = self.penc(tensor)\n",
    "        return enc.permute(0, 4, 1, 2, 3)\n",
    "\n",
    "    @property\n",
    "    def org_channels(self):\n",
    "        return self.penc.org_channels\n",
    "\n",
    "\n",
    "class Summer(nn.Module):\n",
    "    def __init__(self, penc):\n",
    "        \"\"\"\n",
    "        :param model: The type of positional encoding to run the summer on.\n",
    "        \"\"\"\n",
    "        super(Summer, self).__init__()\n",
    "        self.penc = penc\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: A 3, 4 or 5d tensor that matches the model output size\n",
    "        :return: Positional Encoding Matrix summed to the original tensor\n",
    "        \"\"\"\n",
    "        penc = self.penc(tensor)\n",
    "        assert (\n",
    "            tensor.size() == penc.size()\n",
    "        ), \"The original tensor size {} and the positional encoding tensor size {} must match!\".format(\n",
    "            tensor.size(), penc.size()\n",
    "        )\n",
    "        return tensor + penc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "35b229fc-f36d-48a1-8765-b204680eddf3",
   "metadata": {
    "id": "35b229fc-f36d-48a1-8765-b204680eddf3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dense -> MLP             -\\\n",
    "# sparse -> nn.Embedding   --  MLP\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class ElectricyMarketPriceModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dim = 128\n",
    "        self._dense_mlp = nn.Sequential(\n",
    "            nn.LazyLinear(16),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self._month_emb = nn.Embedding(12, embedding_dim)\n",
    "        self._hour_emb = nn.Embedding(24, embedding_dim)\n",
    "        self._weekday_emb = nn.Embedding(7, embedding_dim)\n",
    "        self._node_emb = nn.Embedding(10, embedding_dim)\n",
    "        self._sparse_mlp = nn.Sequential(\n",
    "            nn.LazyLinear(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.pos_encoder = Summer(PositionalEncoding1D(16 + 128))\n",
    "        self._encoder_layer = nn.TransformerEncoderLayer(d_model=16 + 128, nhead=4)\n",
    "        self._transformer_encoder = nn.TransformerEncoder(\n",
    "            self._encoder_layer, num_layers=2\n",
    "        )\n",
    "        self._over_mlp = nn.Sequential(\n",
    "            nn.LazyLinear(64),\n",
    "            nn.Tanh(),\n",
    "            nn.LazyLinear(6),\n",
    "        )\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        dense, sparse, label = batch\n",
    "        # print(f\"dense = {dense}\")\n",
    "        # print(f\"sparse = {sparse}\")\n",
    "        # print(f\"label = {label}\")\n",
    "        # raise Exception()\n",
    "\n",
    "        B = dense.size(0)\n",
    "        dense_out = self._dense_mlp(dense)\n",
    "        month_embs = self._month_emb(sparse[:, :, 0])\n",
    "        hour_embs = self._hour_emb(sparse[:, :, 1])\n",
    "        weekday_embs = self._weekday_emb(sparse[:, :, 2])\n",
    "        node_embs = self._node_emb(sparse[:, :, 3])\n",
    "        sparse_out = self._sparse_mlp(\n",
    "            torch.cat([month_embs, hour_embs, weekday_embs, node_embs], dim=-1)\n",
    "        )\n",
    "        attn_input = self.pos_encoder(torch.cat([dense_out, sparse_out], dim=-1))\n",
    "        # attn_input = self.pos_encoder(dense_out)\n",
    "        attn_output = self._transformer_encoder(attn_input)  # [B, 288, 68]\n",
    "        pred = self._over_mlp(attn_output.view(B, -1))\n",
    "        # print(f'pred {pred}')\n",
    "        # print(f'label {label}')\n",
    "        loss = self.loss(pred, label)\n",
    "        # print(f'loss {loss}')\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.cnn_net(x)\n",
    "        out = out.view(x.size(0), -1)\n",
    "        pred = self.linear_net(out)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        self.log(\"val_loss\", (pred == y).sum().item() / x.size(0), prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        out = self.cnn_net(x)\n",
    "        out = out.view(x.size(0), -1)\n",
    "        pred = self.linear_net(out)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        self.log(\"test_loss\", (pred == y).sum().item() / x.size(0))\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        dense, sparse, label = batch\n",
    "        # print(f\"dense = {dense}\")\n",
    "        # print(f\"sparse = {sparse}\")\n",
    "        # print(f\"label = {label}\")\n",
    "        # raise Exception()\n",
    "\n",
    "        B = dense.size(0)\n",
    "        dense_out = self._dense_mlp(dense)\n",
    "        month_embs = self._month_emb(sparse[:, :, 0])\n",
    "        hour_embs = self._hour_emb(sparse[:, :, 1])\n",
    "        weekday_embs = self._weekday_emb(sparse[:, :, 2])\n",
    "        node_embs = self._node_emb(sparse[:, :, 3])\n",
    "        sparse_out = self._sparse_mlp(\n",
    "            torch.cat([month_embs, hour_embs, weekday_embs, node_embs], dim=-1)\n",
    "        )\n",
    "        attn_input = self.pos_encoder(torch.cat([dense_out, sparse_out], dim=-1))\n",
    "        attn_output = self._transformer_encoder(attn_input)  # [B, 288, 68]\n",
    "        pred = self._over_mlp(attn_output.view(B, -1))\n",
    "        return pred, label\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer, gamma=0.95, verbose=True\n",
    "        )\n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90826f22-de3f-4e5e-9949-80b08c16656f",
   "metadata": {
    "id": "90826f22-de3f-4e5e-9949-80b08c16656f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dateutil\n",
    "\n",
    "node_to_id = {}\n",
    "\n",
    "\n",
    "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, df, years: List[int]):\n",
    "        super(MyIterableDataset).__init__()\n",
    "\n",
    "        self._df = df\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        assert (\n",
    "            worker_info is None\n",
    "        )  # single-process data loading, return the full iterator\n",
    "\n",
    "        price_list: List[float] = []\n",
    "        dense_list: List[List[float]] = []\n",
    "        month_list: List[int] = []\n",
    "        hour_list: List[int] = []\n",
    "        weekday_list: List[int] = []\n",
    "        node_list: List[int] = []\n",
    "\n",
    "        for index, row in self._df.iterrows():\n",
    "            # 24 hours for training, 1 hour for ground truth\n",
    "            if len(price_list) == 24 * 12 + 12 * 24:\n",
    "                indices = list(range(0, 24 * 12, 12))\n",
    "                yield torch.tensor(\n",
    "                    [dense_list[i] for i in indices], dtype=torch.float\n",
    "                ), torch.tensor(\n",
    "                    list(\n",
    "                        zip(\n",
    "                            [month_list[i] for i in indices],\n",
    "                            [hour_list[i] for i in indices],\n",
    "                            [weekday_list[i] for i in indices],\n",
    "                            [node_list[i] for i in indices],\n",
    "                        )\n",
    "                    ),\n",
    "                    dtype=torch.int,\n",
    "                ), torch.tensor(\n",
    "                    [\n",
    "                        price_list[24 * 12],\n",
    "                        price_list[24 * 12 + 11],\n",
    "                        price_list[24 * 12 + 12 * 2 - 1],\n",
    "                        price_list[24 * 12 + 12 * 4 - 1],\n",
    "                        price_list[24 * 12 + 12 * 12 - 1],\n",
    "                        price_list[24 * 12 + 12 * 24 - 1],\n",
    "                    ],\n",
    "                    dtype=torch.float,\n",
    "                ),\n",
    "\n",
    "                # 5 minutes, one hour, 2 hours, 4 hours, 12 hours, 24 hours\n",
    "\n",
    "                price_list.pop(0)\n",
    "                dense_list.pop(0)\n",
    "                month_list.pop(0)\n",
    "                hour_list.pop(0)\n",
    "                weekday_list.pop(0)\n",
    "                node_list.pop(0)\n",
    "\n",
    "            price_list.append(float(row[\"VALUE\"]))\n",
    "            dense_list.append([float(row[\"VALUE\"])] + row[df.columns[-9:]].tolist())\n",
    "            curt_dt = row[\"INTERVALSTARTTIME_GMT\"].to_pydatetime() + timedelta(hours=8)\n",
    "            month_list.append(curt_dt.month - 1)\n",
    "            hour_list.append(curt_dt.hour)\n",
    "            weekday_list.append(curt_dt.weekday())\n",
    "            if row[\"NODE_ID\"] not in node_to_id:\n",
    "                node_to_id[row[\"NODE_ID\"]] = len(node_to_id)\n",
    "            node_list.append(node_to_id[row[\"NODE_ID\"]])\n",
    "\n",
    "\n",
    "train_dataset = MyIterableDataset(df, years=[2020, 2021])\n",
    "test_dataset = MyIterableDataset(df, years=[2022])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb99a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, dataset, buffer_size):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.buffer = list(iter(self.dataset))\n",
    "\n",
    "    def __iter__(self):\n",
    "        buffer = self.buffer\n",
    "        random.shuffle(buffer)\n",
    "        buffer_iter = iter(buffer)\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                try:\n",
    "                    yield next(buffer_iter)\n",
    "                except StopIteration:\n",
    "                    break\n",
    "        except GeneratorExit:\n",
    "            pass\n",
    "\n",
    "\n",
    "shuffled_train_dataset = ShuffleDataset(train_dataset, 12 * 24 * 7 * 30 * 12)\n",
    "shuffled_test_dataset = ShuffleDataset(test_dataset, 12 * 24 * 7 * 30 * 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "04cde994-97ad-443a-9572-28b427536963",
   "metadata": {
    "id": "04cde994-97ad-443a-9572-28b427536963",
    "outputId": "4af23326-e531-416d-aee0-5aff00564a02",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear Linear(in_features=10, out_features=16, bias=True)\n",
      "embedding Embedding(12, 128)\n",
      "embedding Embedding(24, 128)\n",
      "embedding Embedding(7, 128)\n",
      "embedding Embedding(10, 128)\n",
      "linear Linear(in_features=512, out_features=128, bias=True)\n",
      "linear NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)\n",
      "linear Linear(in_features=144, out_features=2048, bias=True)\n",
      "linear Linear(in_features=2048, out_features=144, bias=True)\n",
      "linear NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)\n",
      "linear Linear(in_features=144, out_features=2048, bias=True)\n",
      "linear Linear(in_features=2048, out_features=144, bias=True)\n",
      "linear NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)\n",
      "linear Linear(in_features=144, out_features=2048, bias=True)\n",
      "linear Linear(in_features=2048, out_features=144, bias=True)\n",
      "linear Linear(in_features=3456, out_features=64, bias=True)\n",
      "linear Linear(in_features=64, out_features=6, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/core/module.py:410: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      "/tmp/ipykernel_34292/1710434713.py:4: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4258, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        print(f\"linear {m}\")\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if isinstance(m, nn.Embedding):\n",
    "        print(f\"embedding {m}\")\n",
    "        nn.init.uniform_(m.weight, -1.0, 1.0)\n",
    "\n",
    "\n",
    "module = ElectricyMarketPriceModule()\n",
    "\n",
    "batch = next(iter(DataLoader(train_dataset, batch_size=32)))\n",
    "module.training_step(batch)\n",
    "module.apply(init_weights)\n",
    "module.training_step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "26bdd135-5318-4426-8646-a66b0d32d6d1",
   "metadata": {
    "id": "26bdd135-5318-4426-8646-a66b0d32d6d1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA Graphics Device') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                 | Type                    | Params\n",
      "------------------------------------------------------------------\n",
      "0  | _dense_mlp           | Sequential              | 1.4 K \n",
      "1  | _month_emb           | Embedding               | 1.5 K \n",
      "2  | _hour_emb            | Embedding               | 3.1 K \n",
      "3  | _weekday_emb         | Embedding               | 896   \n",
      "4  | _node_emb            | Embedding               | 1.3 K \n",
      "5  | _sparse_mlp          | Sequential              | 66.7 K\n",
      "6  | pos_encoder          | Summer                  | 0     \n",
      "7  | _encoder_layer       | TransformerEncoderLayer | 1.3 M \n",
      "8  | _transformer_encoder | TransformerEncoder      | 2.6 M \n",
      "9  | _over_mlp            | Sequential              | 34.2 K\n",
      "10 | loss                 | MSELoss                 | 0     \n",
      "------------------------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585006002ad849f6b82daee933722fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0250e-03.\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    callbacks=[lr_monitor],\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"my_model\"),\n",
    "    accelerator=\"gpu\",  # accelerator=\"gpu\",\n",
    ")\n",
    "trainer.fit(module, DataLoader(shuffled_train_dataset, batch_size=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d35e1634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA Graphics Device') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/zyan/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d814fba6e09d4ab3a3d42459201e2f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = trainer.predict(module, DataLoader(shuffled_test_dataset, batch_size=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0f441702-1f55-439f-8ed9-fab233ff7785",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f441702-1f55-439f-8ed9-fab233ff7785",
    "outputId": "ba855b5f-2b69-42e9-bb58-bca24b5b9e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score on Transformer Test set: 0.915\n",
      "MAE Score on Transformer Test set: 0.397\n",
      "MAPE Score on Transformer Test set: 13.683\n",
      "RMSE Score on Transformer Test set: 0.901\n",
      "MAE Score on Transformer Test set: 0.396\n",
      "MAPE Score on Transformer Test set: 8.336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "mses = []\n",
    "maes = []\n",
    "mapes = []\n",
    "\n",
    "start, end = 0, 1\n",
    "\n",
    "for r in res:\n",
    "    pred, test = r\n",
    "    mses.append(np.sqrt(mse(pred[:, start:end], test[:, start:end])))\n",
    "    maes.append(mean_absolute_error(pred[:, start:end], test[:, start:end]))\n",
    "    mapes.append(mean_absolute_percentage_error(pred[:, start:end], test[:, start:end]))\n",
    "\n",
    "print(f\"RMSE Score on Transformer Test set: {sum(mses)/len(mses):0.3f}\")\n",
    "print(f\"MAE Score on Transformer Test set: {sum(maes)/len(maes):0.3f}\")\n",
    "print(f\"MAPE Score on Transformer Test set: {sum(mapes)/len(mapes):0.3f}\")\n",
    "\n",
    "mses.sort()\n",
    "maes.sort()\n",
    "mapes.sort()\n",
    "\n",
    "print(f\"RMSE Score on Transformer Test set: {mses[len(mses)//2]:0.3f}\")\n",
    "print(f\"MAE Score on Transformer Test set: {maes[len(maes)//2]:0.3f}\")\n",
    "print(f\"MAPE Score on Transformer Test set: {mapes[len(mapes)//2]:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fd8b249b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4036929209.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[174], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    RMSE Score on Transformer Test set: 0.580\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "RMSE Score on Transformer Test set: 0.580\n",
    "MAE Score on Transformer Test set: 0.197\n",
    "MAPE Score on Transformer Test set: 2.371"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624307f0-0bf4-4216-960b-6fa2ef9ea3ea",
   "metadata": {
    "id": "624307f0-0bf4-4216-960b-6fa2ef9ea3ea"
   },
   "source": [
    "## Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67741384-f053-4a9d-8fd6-3eadc216bc07",
   "metadata": {
    "id": "67741384-f053-4a9d-8fd6-3eadc216bc07",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# baseline: buy at at 9pm - 9am, sell at 9am - 9pm\n",
    "\n",
    "balance = 0.0\n",
    "charged = 0.0\n",
    "naive_dts = []\n",
    "naive_balances = []\n",
    "naive_remainings = []\n",
    "\n",
    "CAPACITY = 13.3\n",
    "CHARGE_SPEED = 3.3\n",
    "\n",
    "price_list: List[float] = []\n",
    "month_list: List[int] = []\n",
    "hour_list: List[int] = []\n",
    "weekday_list: List[int] = []\n",
    "\n",
    "\n",
    "pbar = tqdm(df.iterrows())\n",
    "for index, row in pbar:\n",
    "    price = float(row[\"VALUE\"])\n",
    "    price_list.append(float(row[\"VALUE\"]))\n",
    "    curt_dt = datetime.strptime(\n",
    "        row[\"INTERVALSTARTTIME_GMT\"], \"%Y-%m-%dT%H:%M:00-00:00\"\n",
    "    ) + timedelta(hours=8)\n",
    "    month_list.append(curt_dt.month - 1)\n",
    "    hour_list.append(curt_dt.hour)\n",
    "    weekday_list.append(curt_dt.weekday())\n",
    "\n",
    "    if curt_dt.year != 2022:\n",
    "        if curt_dt.hour == 0:\n",
    "            pbar.set_description(f\"{curt_dt}\")\n",
    "        continue\n",
    "\n",
    "    # trade at minute 0\n",
    "    if curt_dt.minute == 0:\n",
    "        naive_dts.append(curt_dt)\n",
    "        naive_balances.append(balance)\n",
    "        naive_remainings.append(charged)\n",
    "\n",
    "        if curt_dt.hour >= 9 and curt_dt.hour < 21:\n",
    "            if charged > 0:\n",
    "                balance += price * (CAPACITY / 12)\n",
    "                charged -= CAPACITY / 12\n",
    "        else:\n",
    "            if charged < CAPACITY:\n",
    "                balance -= price * (CAPACITY / 12)\n",
    "                charged += CAPACITY / 12\n",
    "\n",
    "        if curt_dt.hour == 0:\n",
    "            pbar.set_description(f\"{curt_dt} {balance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1251ed6-382c-4944-9dea-a3c504ea664d",
   "metadata": {
    "id": "f1251ed6-382c-4944-9dea-a3c504ea664d",
    "outputId": "af63484b-7bc5-4c97-b1e2-2780f3d2f7b3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(dts, balances, label=\"ML\")\n",
    "plt.plot(naive_dts, naive_balances, label=\"Naive\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Balance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b39a0",
   "metadata": {
    "id": "c7d55b77-cbfe-467f-b382-dddc7436a7b5"
   },
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80031b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "\n",
    "\n",
    "class TimeSeriesForecastingEnv(gym.Env):\n",
    "    def __init__(self, dataset, window_size, categorical_columns, numerical_columns):\n",
    "        super(TimeSeriesForecastingEnv, self).__init__()\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.window_size = window_size\n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.numerical_columns = numerical_columns\n",
    "        self.current_step = 0\n",
    "\n",
    "        self.action_space = spaces.Discrete(3)  # Buy, hold, sell\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=1,\n",
    "            shape=(window_size, len(categorical_columns + numerical_columns)),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return self.dataset[self.current_step : self.current_step + self.window_size]\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        done = self.current_step >= len(self.dataset) - self.window_size\n",
    "        reward = 0  # Replace this with a suitable reward function for your problem\n",
    "\n",
    "        return observation, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b670b11-f216-47d5-ad4c-acee41dbb123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyVecEnv\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load and preprocess your dataset\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myour_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m categorical_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_col1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_col2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m numerical_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_col1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_col2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "data = pd.read_csv(\"your_dataset.csv\")\n",
    "categorical_columns = [\"cat_col1\", \"cat_col2\"]\n",
    "numerical_columns = [\"num_col1\", \"num_col2\"]\n",
    "window_size = 10\n",
    "\n",
    "# Preprocess your data (normalize, encode categorical variables, etc.)\n",
    "# ...\n",
    "\n",
    "env = TimeSeriesForecastingEnv(\n",
    "    data, window_size, categorical_columns, numerical_columns\n",
    ")\n",
    "env = DummyVecEnv([lambda: env])  # PPO requires a vectorized environment\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15ce671-8f18-4ac4-aa5d-1ee8fbb417d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(action)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[0;32m---> 11\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predict(\u001b[43mmodel\u001b[49m, data, window_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def predict(model, data, window_size):\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(len(data) - window_size):\n",
    "        obs = data[i : i + window_size]\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        predictions.append(action)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predictions = predict(model, data, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edcf0ba-536f-4b43-b7c9-c691f2967fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
